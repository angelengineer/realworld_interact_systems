{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "intro_info_title"
    ]
   },
   "source": [
    "<link rel=\"stylesheet\" href=\"../../styles/theme_style.css\">\n",
    "<!--link rel=\"stylesheet\" href=\"../../styles/header_style.css\"-->\n",
    "<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css\">\n",
    "\n",
    "<table width=\"100%\">\n",
    "    <tr>\n",
    "        <td id=\"image_td\" width=\"15%\" class=\"header_image_color_7\"><div id=\"image_img\"\n",
    "        class=\"header_image_7\"></div></td>\n",
    "        <td class=\"header_text\"> Stone, Paper or Scissor Game - Train and Classify [Volume 3] </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "intro_info_tags"
    ]
   },
   "source": [
    "<div id=\"flex-container\">\n",
    "    <div id=\"diff_level\" class=\"flex-item\">\n",
    "        <strong>Difficulty Level:</strong>   <span class=\"fa fa-star checked\"></span>\n",
    "                                <span class=\"fa fa-star checked\"></span>\n",
    "                                <span class=\"fa fa-star checked\"></span>\n",
    "                                <span class=\"fa fa-star\"></span>\n",
    "                                <span class=\"fa fa-star\"></span>\n",
    "    </div>\n",
    "    <div id=\"tag\" class=\"flex-item-tag\">\n",
    "        <span id=\"tag_list\">\n",
    "            <table id=\"tag_list_table\">\n",
    "                <tr>\n",
    "                    <td class=\"shield_left\">Tags</td>\n",
    "                    <td class=\"shield_right\" id=\"tags\">train_and_classify&#9729;machine-learning&#9729;features&#9729;selection</td>\n",
    "                </tr>\n",
    "            </table>\n",
    "        </span>\n",
    "        <!-- [OR] Visit https://img.shields.io in order to create a tag badge-->\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "test"
    ]
   },
   "source": [
    "<span class=\"color4\"><strong>Previous Notebooks that are part of \"Rock, Paper or Scissor Game - Train and Classify\" module</strong></span>\n",
    "<ul>\n",
    "    <li><a href=\"classification_game_volume_1.ipynb\"><strong>Rock, Paper or Scissor Game - Train and Classify [Volume 1] | Experimental Setup <img src=\"../../images/icons/link.png\" width=\"10px\" height=\"10px\" style=\"display:inline\"></strong></a></li>\n",
    "    <li><a href=\"classification_game_volume_2.ipynb\"><strong>Rock, Paper or Scissor Game - Train and Classify [Volume 2] | Feature Extraction <img src=\"../../images/icons/link.png\" width=\"10px\" height=\"10px\" style=\"display:inline\"></strong></a></li>\n",
    "</ul>\n",
    "\n",
    "<span class=\"color7\"><strong>Following Notebooks that are part of \"Rock, Paper or Scissor Game - Train and Classify\" module</strong></span>\n",
    "<ul>\n",
    "    <li><a href=\"classification_game_volume_4.ipynb\"><strong>Rock, Paper or Scissor Game - Train and Classify [Volume 4] | Training a Classifier <img src=\"../../images/icons/link.png\" width=\"10px\" height=\"10px\" style=\"display:inline\"></strong></a></li>\n",
    "    <li><a href=\"../Evaluate/classification_game_volume_5.ipynb\"><strong>Rock, Paper or Scissor Game - Train and Classify [Volume 5] | Performance Evaluation <img src=\"../../images/icons/link.png\" width=\"10px\" height=\"10px\" style=\"display:inline\"></strong></a></li>\n",
    "</ul>  \n",
    "\n",
    "<table width=\"100%\">\n",
    "    <tr>\n",
    "        <td style=\"text-align:left;font-size:12pt;border-top:dotted 2px #62C3EE\">\n",
    "            <span class=\"color1\">&#9740;</span> Currently we are in possession of a file containing the feature values for all training examples, as demonstrated on a previously created <a href=\"classification_game_volume_2.ipynb\">Jupyter Notebook <img src=\"../../images/icons/link.png\" width=\"10px\" height=\"10px\" style=\"display:inline\"></a>.\n",
    "            <br>\n",
    "            However, there is a high risk that some of the extracted features are not useful for our classification system. Remember, a good feature is a parameter that has the ability to separate the different classes of our classification system, i.e, a parameter with a characteristic range of values for each available class.\n",
    "            <br>\n",
    "            In order to ensure that the training process of our classifier happens in the most efficient way, these redundant or invariant features should be removed.\n",
    "            <br>\n",
    "            The implicit logic of the last two paragraphs is called <span class=\"color7\"><strong>Feature Selection</strong></span>, which will be focused at this <span class=\"color4\"><strong>Jupyter Notebook</strong></span> !\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20pt;color:#62C3EE;padding-bottom:5pt\">Starting Point (Setup)</p>\n",
    "<strong>List of Available Classes:</strong>\n",
    "<br>\n",
    "<ol start=\"0\">\n",
    "    <li><span class=\"color1\"><strong>\"No Action\"</strong></span> [When the hand is relaxed]</li>\n",
    "    <li><span class=\"color4\"><strong>\"Paper\"</strong></span> [All fingers are extended]</li>\n",
    "    <li><span class=\"color7\"><strong>\"Stone\"</strong></span> [All fingers are bent]</li>\n",
    "    <li><span class=\"color13\"><strong>\"Scissor\"</strong></span> [Forefinger and middle finger are extended and the remaining ones are bent]</li>\n",
    "</ol>\n",
    "<table align=\"center\">\n",
    "    <tr>\n",
    "        <td height=\"200px\">\n",
    "            <img src=\"../../images/train_and_classify/classification_game_volume_3/classification_game_paper.png\" style=\"display:block;height:100%\">\n",
    "        </td>\n",
    "        <td height=\"200px\">\n",
    "            <img src=\"../../images/train_and_classify/classification_game_volume_3/classification_game_stone.png\" style=\"display:block;height:100%\">\n",
    "        </td>\n",
    "        <td height=\"200px\">\n",
    "            <img src=\"../../images/train_and_classify/classification_game_volume_3/classification_game_scissor.png\" style=\"display:block;height:100%\">\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:center\">\n",
    "            <strong>Paper</strong>\n",
    "        </td>\n",
    "        <td style=\"text-align:center\">\n",
    "            <strong>Stone</strong>\n",
    "        </td>\n",
    "        <td style=\"text-align:center\">\n",
    "            <strong>Scissor</strong>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<strong>Acquired Data:</strong>\n",
    "<br>\n",
    "<ul>\n",
    "    <li>Electromyography (EMG) | 2 muscles | Adductor pollicis and  Flexor digitorum superficialis</li>\n",
    "    <li>Accelerometer (ACC) | 1 axis | Sensor parallel to the thumb nail (Axis perpendicular)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20pt;color:#62C3EE;padding-bottom:5pt\">Protocol/Feature Extraction</p>\n",
    "<strong>Extracted Features</strong>\n",
    "<ul>\n",
    "    <li><span style=\"color:#E84D0E\"><strong>[From] EMG signal</strong></span></li>\n",
    "    <ul>\n",
    "        <li>Standard Deviation &#9734;</li>\n",
    "        <li>Maximum sampled value &#9757;</li>\n",
    "       <li><a href=\"https://en.wikipedia.org/wiki/Zero-crossing_rate\">Zero-Crossing Rate</a> &#9740;</li>\n",
    "        <li>Standard Deviation of the absolute signal &#9735;</li>\n",
    "    </ul>\n",
    "    <li><span style=\"color:#FDC400\"><strong>[From] ACC signal</strong></span></li>\n",
    "    <ul>\n",
    "        <li>Average Value &#9737;</li>\n",
    "        <li>Standard Deviation &#9734;</li>\n",
    "        <li>Maximum sampled value &#9757;</li>\n",
    "        <li><a href=\"https://en.wikipedia.org/wiki/Zero-crossing_rate\">Zero-Crossing Rate</a> &#9740;</li>\n",
    "        <li><a href=\"https://en.wikipedia.org/wiki/Slope\">Slope of the regression curve</a> &#9741;</li>\n",
    "    </ul>\n",
    "</ul>\n",
    "\n",
    "<strong>Formal definition of parameters</strong>\n",
    "<br>\n",
    "&#9757; | Maximum Sample Value of a set of elements is equal to the last element of the sorted set\n",
    "\n",
    "&#9737; | $\\mu = \\frac{1}{N}\\sum_{i=1}^N (sample_i)$\n",
    "\n",
    "&#9734; | $\\sigma = \\sqrt{\\frac{1}{N}\\sum_{i=1}^N(sample_i - \\mu_{signal})^2}$\n",
    "\n",
    "&#9740; | $zcr = \\frac{1}{N - 1}\\sum_{i=1}^{N-1}bin(i)$ \n",
    "\n",
    "&#9735; | $\\sigma_{abs} = \\sqrt{\\frac{1}{N}\\sum_{i=1}^N(|sample_i| - \\mu_{signal_{abs}})^2}$\n",
    "\n",
    "&#9741; | $m = \\frac{\\Delta signal}{\\Delta t}$\n",
    "\n",
    "... being $N$ the number of acquired samples (that are part of the signal), $sample_i$ the value of the sample number $i$, $signal_{abs}$ the absolute signal, $\\Delta signal$ is the difference between the y coordinate of two points of the regression curve and $\\Delta t$ the difference between the x (time) coordinate of the same two points of the regression curve.\n",
    "\n",
    "... and \n",
    "\n",
    "$bin(i)$ a binary function defined as:\n",
    "\n",
    "$bin(i) = \\begin{cases} 1, & \\mbox{if } signal_i \\times signal_{i-1} \\leq 0 \\\\ 0, & \\mbox{if } signal_i \\times signal_{i-1}>0 \\end{cases}$\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20pt;color:#62C3EE;padding-bottom:5pt\">Feature Selection</p>\n",
    "<strong>Intro</strong>\n",
    "<br>\n",
    "With <span class=\"color7\"><strong>Feature Selection</strong></span> we will start to use the resources contained inside an extremely useful <span class=\"color1\"><strong>Python</strong></span> package: <a href=\"https://scikit-learn.org/stable/index.html\">scikit-learn <img src=\"../../images/icons/link.png\" width=\"10px\" height=\"10px\" style=\"display:inline\"></a>\n",
    "\n",
    "Like described before, <span class=\"color7\"><strong>Feature Selection</strong></span> is intended to remove redundant or meaningless parameters which would increase the complexity of the classifier and not always translate into an improved performance. Without this step, the risk of overfitting to the training examples increases, making the classifier less able to categorize a new testing example.\n",
    "\n",
    "There are different approaches to feature selection such as <span class=\"color4\"><strong>filter methods</strong></span> or <span class=\"color1\"><strong>wrapper methods</strong></span>.\n",
    "\n",
    "In the first method (<span class=\"color4\"><strong>filter methods</strong></span>), a ranking will be attributed to the features, using, for example, the <strong>Pearson correlation coefficient</strong> to evaluate the impact that the feature under analysis has on the target class of the training example, or the <strong>Mutual Information parameter</strong> which defines whether two variables convey shared information. \n",
    "\n",
    "The least relevant features will be excluded and the classifier will be trained later (for a deeper explanation, please, visit the article of Girish Chandrashekar and Ferat Sahin at <a href=\"https://www.sciencedirect.com/science/article/pii/S0045790613003066\"><strong>ScienceDirect <img src=\"../../images/icons/link.png\" width=\"10px\" height=\"10px\" style=\"display:inline\"></strong></a>).\n",
    "\n",
    "The second methodology (<span class=\"color1\"><strong>wrapper methods</strong></span>) is characterised by the fact that the selection phase includes a classification algorithm, and features will be excluded or selected according to the quality of the trained classifier.\n",
    "\n",
    "There are also a third major methodology applicable on <span class=\"color7\"><strong>Feature Selection</strong></span>, including the so called <span class=\"color13\"><strong>embedded methods</strong></span>. Essentially this methods are a combination of <span class=\"color4\"><strong>filter</strong></span> and <span class=\"color1\"><strong>wrapper</strong></span>, being characterised by the simultaneous execution of <span class=\"color7\"><strong>Feature Selection</strong></span> and <span class=\"color13\"><strong>Training</strong></span> stages.\n",
    "\n",
    "One of the most intuitive <span class=\"color7\"><strong>Feature Selection</strong></span> methods is <span class=\"color1\"><strong>Recursive Feature Elimination</strong></span>, which will be used in the current <span class=\"color4\"><strong>Jupyter Notebook</strong></span>.\n",
    "\n",
    "Essentially the steps of this method consists in:\n",
    "<ol>\n",
    "    <li>Original set of training examples is segmented into multiple ($K$) subsets of training examples and test examples</li>\n",
    "    For each one of the $K$ subsets of training/test examples:\n",
    "    <ol>\n",
    "        <li>The training examples are used for training a \"virtual\" classifier (for example a <a href=\"https://en.wikipedia.org/wiki/Support-vector_machine\"><strong>Support Vector Machine <img src=\"../../images/icons/link.png\" width=\"10px\" height=\"10px\" style=\"display:inline\"></strong></a>)</li>\n",
    "        <li>The test examples are given as inputs of the trained classifier and the \"virtual\" classifier quality is estimated</li>\n",
    "    </ol>\n",
    "    <li>At this point we can estimate the average quality of the $K$ \"virtual\" classifiers and know the weight of each feature on the training stage</li>\n",
    "    <li>The feature with a smaller weight is excluded</li>\n",
    "    <li>Repetition of steps <strong>1</strong>, <strong>2</strong> and <strong>3</strong> until only one feature remains</li>\n",
    "    <li>Finally, when the \"feature elimination\" procedure ends, the set of features that provide a \"virtual\" classifier with the best average quality (step <strong>2</strong>) define the relevant features to be used during our final training stage</li>\n",
    "</ol> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"steps\">0 - Import of the needed packages for a correct execution of the current <span class=\"color4\">Jupyter Notebook</span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_out"
    ]
   },
   "outputs": [],
   "source": [
    "# Python package that contains functions specialized on \"Machine Learning\" tasks.\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV, RFE\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Package dedicated to the manipulation of json files.\n",
    "from json import loads, dump\n",
    "\n",
    "# Package containing a diversified set of function for statistical processing and also provide support to array operations.\n",
    "from numpy import max, array\n",
    "\n",
    "# biosignalsnotebooks own package that supports some functionalities used on the Jupyter Notebooks.\n",
    "import biosignalsnotebooks as bsnb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"steps\">1 - Loading of the dictionary created on <a href=\"classification_game_volume_2.ipynb\">Volume 2 of \"Classification Game\" Jupyter Notebook <img src=\"../../images/icons/link.png\" width=\"10px\" height=\"10px\" style=\"display:inline\"></a></p>\n",
    "This dictionary contains all the features extracted from our training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specification of filename and relative path.\n",
    "relative_path = \"/home/ferdinand/realworld_interact_systems/features\"\n",
    "data_folder = \"/home/ferdinand/realworld_interact_systems/data\"\n",
    "filename = \"classification_game_features.json\"\n",
    "\n",
    "# Load of data inside file storing it inside a Python dictionary.\n",
    "with open(relative_path + \"/\" + filename) as file:\n",
    "    features_dict = loads(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_in"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;98;195;238m\u001b[1mDict Keys\u001b[0m\u001b[39m define the class number\n",
      "\u001b[38;2;232;77;14m\u001b[1mDict Sub-Keys\u001b[0m\u001b[39m define the trial number\n",
      "\n",
      "{'3': {'5': [2.8147020649020488e-05, -1.4998626708984375, 0.0, 2.8147020649020488e-05, 0.0009411571726303267, -1.469696044921875, 0.0, 0.0009411571726303267, -6.485221005555555, 0.004836235489622132, -6.46579, 0.0, -2.0671109484224937e-06], '2': [5.548697320634877e-05, -1.49981689453125, 0.0, 5.548697320634877e-05, 0.0012061097236280257, -1.4590301513671875, 0.0, 0.0012061097236280257, -6.4848515873873875, 0.0053641986364910315, -6.4454, 0.0, -1.8129640753796555e-06], '4': [1.4448836982117904e-05, -1.4999542236328125, 0.0, 1.4448836982117904e-05, 0.001252298795212228, -1.4642486572265625, 0.0, 0.001252298795212228, -6.485075392592593, 0.007293596163348992, -6.3959, 0.0, -1.5360765158690952e-06], '3': [1.4448836982117904e-05, -1.4999542236328125, 0.0, 1.4448836982117904e-05, 0.0010568122871173681, -1.4647064208984375, 0.0, 0.0010568122871173681, -6.485149444444445, 0.005924511471238735, -6.4366, 0.0, -2.0267690894715596e-06], '1': [5.554121469901836e-05, -1.49981689453125, 0.0, 5.554121469901836e-05, 0.0011593335437198372, -1.4631500244140625, 0.0, 0.0011593335437198372, -6.48350207047619, 0.006772801499470012, -6.4314, 0.0, -1.8125123402531067e-06]}, '1': {'2': [1.3982274378391871e-05, -1.4999542236328125, 0.0, 1.3982274378391871e-05, 0.0012319227810117907, -1.460540771484375, 0.0, 0.0012319227810117907, -6.4832644684684695, 0.0039949995587272675, -6.42879, 0.0, -1.4844371327565837e-06], '4': [5.558889080895551e-05, -1.49981689453125, 0.0, 5.558889080895551e-05, 0.0012019167309204686, -1.4626922607421875, 0.0, 0.0012019167309204686, -6.48106052962963, 0.0034059748614059244, -6.45239, 0.0, -1.1830831323264056e-06], '5': [1.4460650826380089e-05, -1.4999542236328125, 0.0, 1.4460650826380089e-05, 0.0011759606813691748, -1.464385986328125, 0.0, 0.0011759606813691748, -6.481200655855855, 0.003238617717947911, -6.44939, 0.0, -9.249022660247164e-07], '3': [1.448086583109432e-05, -1.4999542236328125, 0.0, 1.448086583109432e-05, 0.0018116347807403438, -1.453216552734375, 0.0, 0.0018116347807403438, -6.484591448648648, 0.0045966741355707415, -6.4518, 0.0, -4.923768513155715e-07], '1': [1.403290196774536e-05, -1.4999542236328125, 0.0, 1.403290196774536e-05, 0.0013467510723971943, -1.4622802734375, 0.0, 0.0013467510723971943, -6.483004716666666, 0.0051676954381953254, -6.44559, 0.0, -1.4928694723968692e-06]}, '0': {'3': [2.8211654275041983e-05, -1.4998626708984375, 0.0, 2.8211654275041983e-05, 0.0001229975705213289, -1.4761962890625, 0.0, 0.0001229975705213289, -6.478157198245614, 0.000201255426420253, -6.4774, 0.0, 2.3861297327704272e-08], '5': [1.3967118118793665e-05, -1.4999542236328125, 0.0, 1.3967118118793665e-05, 0.00012260201937285253, -1.476104736328125, 0.0, 0.00012260201937285253, -6.477414419444446, 0.0002024553357045387, -6.47639, 0.0, 2.02663069753007e-09], '1': [1.4447312773576076e-05, -1.4999542236328125, 0.0, 1.4447312773576076e-05, 0.0002250022192921037, -1.47564697265625, 0.0, 0.0002250022192921037, -6.478087375609756, 0.00018522815741522675, -6.47759, 0.0, -7.383330739521648e-09], '2': [5.5504245763894074e-05, -1.49981689453125, 0.0, 5.5504245763894074e-05, 0.0009758269878049337, -1.46905517578125, 0.0, 0.0009758269878049337, -6.476616274074075, 0.0009104937645332033, -6.474, 0.0, 9.617666844053747e-09], '4': [1.4021972237440932e-05, -1.4999542236328125, 0.0, 1.4021972237440932e-05, 0.00014335429756520376, -1.4758758544921875, 0.0, 0.00014335429756520376, -6.477423801851853, 0.00020145004342655846, -6.47679, 0.0, 5.342865485770648e-08]}, '2': {'3': [5.5461540508782287e-05, -1.49981689453125, 0.0, 5.5461540508782287e-05, 0.002556928526702708, -1.453216552734375, 0.0, 0.002556928526702708, -6.476643316666667, 0.003999162359019227, -6.3959, 0.0, 1.9270462061551232e-07], '2': [1.4500754098654718e-05, -1.4999542236328125, 0.0, 1.4500754098654718e-05, 0.0028932706468857744, -1.453216552734375, 0.0, 0.0028932706468857744, -6.476072375925925, 0.003227307759339755, -6.3962, 0.0, 1.493551099078168e-07], '1': [1.4479134958699508e-05, -1.4999542236328125, 0.0, 1.4479134958699508e-05, 0.0035583103960313374, -1.453216552734375, 0.0, 0.0035583103960313374, -6.4766904019047615, 0.004095075864219208, -6.3962, 0.0, 5.534272233961219e-07], '5': [1.400362692658915e-05, -1.4999542236328125, 0.0, 1.400362692658915e-05, 0.0028721206865606644, -1.453216552734375, 0.0, 0.0028721206865606644, -6.476721261261261, 0.002942591619006456, -6.424, 0.0, 2.647026865527182e-07], '4': [5.5487622571979205e-05, -1.49981689453125, 0.0, 5.5487622571979205e-05, 0.0018954331990501563, -1.4533538818359375, 0.0, 0.0018954331990501563, -6.476488053703703, 0.0015069825409066452, -6.45859, 0.0, 5.432098323002899e-07]}}\n"
     ]
    }
   ],
   "source": [
    "from sty import fg, rs\n",
    "print(fg(98,195,238) + \"\\033[1mDict Keys\\033[0m\" + fg.rs + \" define the class number\")\n",
    "print(fg(232,77,14) + \"\\033[1mDict Sub-Keys\\033[0m\" + fg.rs + \" define the trial number\\n\")\n",
    "print(features_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"steps\">2 - Restructuring of \"features_dict\" to a compatible format of <a href=\"https://scikit-learn.org/stable/index.html\">scikit-learn <img src=\"../../images/icons/link.png\" width=\"10px\" height=\"10px\" style=\"display:inline\"></a> package</p>\n",
    "features_dict must be converted to a list, containing inside it a number of sub-lists equal to the number of training examples (in our case 20). In its turn, each sub-list is formed by a number of entries equal to the number of extracted features (13 for our original formulation of the problem)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['3', '1', '0', '2'])\n",
      "dict_keys(['3', '1', '0', '2'])\n"
     ]
    }
   ],
   "source": [
    "print(features_dict.keys())\n",
    "print(features_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation of a list containing our training data and another list containing the labels of each training example.\n",
    "features_list = []\n",
    "class_training_examples = []\n",
    "\n",
    "# Access each feature list inside dictionary.\n",
    "list_classes = features_dict.keys()\n",
    "for class_i in list_classes:\n",
    "    list_trials = features_dict[class_i].keys()\n",
    "    for trial in list_trials:\n",
    "        # Storage of the class label.\n",
    "        class_training_examples += [int(class_i)]\n",
    "        features_list += [features_dict[class_i][trial]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_in"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;232;77;14m\u001b[1m[Number of list entries;Number of sub-list entries]:\u001b[0m\u001b[39m [20; 13]✓\n",
      "\u001b[38;2;253;196;0m\u001b[1mClass of each training example:\u001b[0m\u001b[39m\n",
      "[3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2]\n",
      "\u001b[38;2;98;195;238m\u001b[1mFeatures List:\u001b[0m\u001b[39m\n",
      "[[2.8147020649020488e-05, -1.4998626708984375, 0.0, 2.8147020649020488e-05, 0.0009411571726303267, -1.469696044921875, 0.0, 0.0009411571726303267, -6.485221005555555, 0.004836235489622132, -6.46579, 0.0, -2.0671109484224937e-06], [5.548697320634877e-05, -1.49981689453125, 0.0, 5.548697320634877e-05, 0.0012061097236280257, -1.4590301513671875, 0.0, 0.0012061097236280257, -6.4848515873873875, 0.0053641986364910315, -6.4454, 0.0, -1.8129640753796555e-06], [1.4448836982117904e-05, -1.4999542236328125, 0.0, 1.4448836982117904e-05, 0.001252298795212228, -1.4642486572265625, 0.0, 0.001252298795212228, -6.485075392592593, 0.007293596163348992, -6.3959, 0.0, -1.5360765158690952e-06], [1.4448836982117904e-05, -1.4999542236328125, 0.0, 1.4448836982117904e-05, 0.0010568122871173681, -1.4647064208984375, 0.0, 0.0010568122871173681, -6.485149444444445, 0.005924511471238735, -6.4366, 0.0, -2.0267690894715596e-06], [5.554121469901836e-05, -1.49981689453125, 0.0, 5.554121469901836e-05, 0.0011593335437198372, -1.4631500244140625, 0.0, 0.0011593335437198372, -6.48350207047619, 0.006772801499470012, -6.4314, 0.0, -1.8125123402531067e-06], [1.3982274378391871e-05, -1.4999542236328125, 0.0, 1.3982274378391871e-05, 0.0012319227810117907, -1.460540771484375, 0.0, 0.0012319227810117907, -6.4832644684684695, 0.0039949995587272675, -6.42879, 0.0, -1.4844371327565837e-06], [5.558889080895551e-05, -1.49981689453125, 0.0, 5.558889080895551e-05, 0.0012019167309204686, -1.4626922607421875, 0.0, 0.0012019167309204686, -6.48106052962963, 0.0034059748614059244, -6.45239, 0.0, -1.1830831323264056e-06], [1.4460650826380089e-05, -1.4999542236328125, 0.0, 1.4460650826380089e-05, 0.0011759606813691748, -1.464385986328125, 0.0, 0.0011759606813691748, -6.481200655855855, 0.003238617717947911, -6.44939, 0.0, -9.249022660247164e-07], [1.448086583109432e-05, -1.4999542236328125, 0.0, 1.448086583109432e-05, 0.0018116347807403438, -1.453216552734375, 0.0, 0.0018116347807403438, -6.484591448648648, 0.0045966741355707415, -6.4518, 0.0, -4.923768513155715e-07], [1.403290196774536e-05, -1.4999542236328125, 0.0, 1.403290196774536e-05, 0.0013467510723971943, -1.4622802734375, 0.0, 0.0013467510723971943, -6.483004716666666, 0.0051676954381953254, -6.44559, 0.0, -1.4928694723968692e-06], [2.8211654275041983e-05, -1.4998626708984375, 0.0, 2.8211654275041983e-05, 0.0001229975705213289, -1.4761962890625, 0.0, 0.0001229975705213289, -6.478157198245614, 0.000201255426420253, -6.4774, 0.0, 2.3861297327704272e-08], [1.3967118118793665e-05, -1.4999542236328125, 0.0, 1.3967118118793665e-05, 0.00012260201937285253, -1.476104736328125, 0.0, 0.00012260201937285253, -6.477414419444446, 0.0002024553357045387, -6.47639, 0.0, 2.02663069753007e-09], [1.4447312773576076e-05, -1.4999542236328125, 0.0, 1.4447312773576076e-05, 0.0002250022192921037, -1.47564697265625, 0.0, 0.0002250022192921037, -6.478087375609756, 0.00018522815741522675, -6.47759, 0.0, -7.383330739521648e-09], [5.5504245763894074e-05, -1.49981689453125, 0.0, 5.5504245763894074e-05, 0.0009758269878049337, -1.46905517578125, 0.0, 0.0009758269878049337, -6.476616274074075, 0.0009104937645332033, -6.474, 0.0, 9.617666844053747e-09], [1.4021972237440932e-05, -1.4999542236328125, 0.0, 1.4021972237440932e-05, 0.00014335429756520376, -1.4758758544921875, 0.0, 0.00014335429756520376, -6.477423801851853, 0.00020145004342655846, -6.47679, 0.0, 5.342865485770648e-08], [5.5461540508782287e-05, -1.49981689453125, 0.0, 5.5461540508782287e-05, 0.002556928526702708, -1.453216552734375, 0.0, 0.002556928526702708, -6.476643316666667, 0.003999162359019227, -6.3959, 0.0, 1.9270462061551232e-07], [1.4500754098654718e-05, -1.4999542236328125, 0.0, 1.4500754098654718e-05, 0.0028932706468857744, -1.453216552734375, 0.0, 0.0028932706468857744, -6.476072375925925, 0.003227307759339755, -6.3962, 0.0, 1.493551099078168e-07], [1.4479134958699508e-05, -1.4999542236328125, 0.0, 1.4479134958699508e-05, 0.0035583103960313374, -1.453216552734375, 0.0, 0.0035583103960313374, -6.4766904019047615, 0.004095075864219208, -6.3962, 0.0, 5.534272233961219e-07], [1.400362692658915e-05, -1.4999542236328125, 0.0, 1.400362692658915e-05, 0.0028721206865606644, -1.453216552734375, 0.0, 0.0028721206865606644, -6.476721261261261, 0.002942591619006456, -6.424, 0.0, 2.647026865527182e-07], [5.5487622571979205e-05, -1.49981689453125, 0.0, 5.5487622571979205e-05, 0.0018954331990501563, -1.4533538818359375, 0.0, 0.0018954331990501563, -6.476488053703703, 0.0015069825409066452, -6.45859, 0.0, 5.432098323002899e-07]]\n"
     ]
    }
   ],
   "source": [
    "print(fg(232,77,14) + \"\\033[1m[Number of list entries;Number of sub-list entries]:\\033[0m\" + fg.rs + \" [\" + str(len(features_list)) + \"; \" + str(len(features_list[0])) + \"]\" + u'\\u2713')\n",
    "print(fg(253,196,0) + \"\\033[1mClass of each training example:\\033[0m\" + fg.rs)\n",
    "print(class_training_examples)\n",
    "print(fg(98,195,238) + \"\\033[1mFeatures List:\\033[0m\" + fg.rs)\n",
    "print(features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"steps\">2.1 - Normalisation of the features values, ensuring that the training stage is not affected by scale factors</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = normalize(features_list, axis=0, norm=\"max\") # axis=0 specifies that each feature is normalised independently from the others \n",
    "                                                             # and norm=\"max\" defines that the normalization reference value will be the feature maximum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_in"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.06342549e-01 -9.99938963e-01  0.00000000e+00  5.06342549e-01\n",
      "   2.64495524e-01 -9.95596626e-01  0.00000000e+00  2.64495524e-01\n",
      "  -1.00000000e+00  6.63079691e-01 -9.98178335e-01  0.00000000e+00\n",
      "  -1.00000000e+00]\n",
      " [ 9.98166583e-01 -9.99908444e-01  0.00000000e+00  9.98166583e-01\n",
      "   3.38955737e-01 -9.88371372e-01  0.00000000e+00  3.38955737e-01\n",
      "  -9.99943037e-01  7.35466910e-01 -9.95030559e-01  0.00000000e+00\n",
      "  -8.77052137e-01]\n",
      " [ 2.59923103e-01 -1.00000000e+00  0.00000000e+00  2.59923103e-01\n",
      "   3.51936356e-01 -9.91906475e-01  0.00000000e+00  3.51936356e-01\n",
      "  -9.99977547e-01  1.00000000e+00 -9.87388828e-01  0.00000000e+00\n",
      "  -7.43103082e-01]\n",
      " [ 2.59923103e-01 -1.00000000e+00  0.00000000e+00  2.59923103e-01\n",
      "   2.96998342e-01 -9.92216572e-01  0.00000000e+00  2.96998342e-01\n",
      "  -9.99988966e-01  8.12289485e-01 -9.93672029e-01  0.00000000e+00\n",
      "  -9.80483941e-01]\n",
      " [ 9.99142345e-01 -9.99908444e-01  0.00000000e+00  9.99142345e-01\n",
      "   3.25810122e-01 -9.91162243e-01  0.00000000e+00  3.25810122e-01\n",
      "  -9.99734946e-01  9.28595627e-01 -9.92869262e-01  0.00000000e+00\n",
      "  -8.76833603e-01]\n",
      " [ 2.51530012e-01 -1.00000000e+00  0.00000000e+00  2.51530012e-01\n",
      "   3.46210039e-01 -9.89394691e-01  0.00000000e+00  3.46210039e-01\n",
      "  -9.99698308e-01  5.47740712e-01 -9.92466334e-01  0.00000000e+00\n",
      "  -7.18121654e-01]\n",
      " [ 1.00000000e+00 -9.99908444e-01  0.00000000e+00  1.00000000e+00\n",
      "   3.37777371e-01 -9.90852146e-01  0.00000000e+00  3.37777371e-01\n",
      "  -9.99358468e-01  4.66981553e-01 -9.96109664e-01  0.00000000e+00\n",
      "  -5.72336542e-01]\n",
      " [ 2.60135625e-01 -1.00000000e+00  0.00000000e+00  2.60135625e-01\n",
      "   3.30482884e-01 -9.91999504e-01  0.00000000e+00  3.30482884e-01\n",
      "  -9.99380075e-01  4.44035788e-01 -9.95646529e-01  0.00000000e+00\n",
      "  -4.47437167e-01]\n",
      " [ 2.60499276e-01 -1.00000000e+00  0.00000000e+00  2.60499276e-01\n",
      "   5.09127810e-01 -9.84433143e-01  0.00000000e+00  5.09127810e-01\n",
      "  -9.99902924e-01  6.30234254e-01 -9.96018581e-01  0.00000000e+00\n",
      "  -2.38195657e-01]\n",
      " [ 2.52440762e-01 -1.00000000e+00  0.00000000e+00  2.52440762e-01\n",
      "   3.78480493e-01 -9.90573059e-01  0.00000000e+00  3.78480493e-01\n",
      "  -9.99658255e-01  7.08525030e-01 -9.95059891e-01  0.00000000e+00\n",
      "  -7.22200941e-01]\n",
      " [ 5.07505256e-01 -9.99938963e-01  0.00000000e+00  5.07505256e-01\n",
      "   3.45662848e-02 -1.00000000e+00  0.00000000e+00  3.45662848e-02\n",
      "  -9.98910784e-01  2.75934425e-02 -9.99970668e-01  0.00000000e+00\n",
      "   1.15433075e-02]\n",
      " [ 2.51257363e-01 -1.00000000e+00  0.00000000e+00  2.51257363e-01\n",
      "   3.44551222e-02 -9.99937981e-01  0.00000000e+00  3.44551222e-02\n",
      "  -9.98796250e-01  2.77579580e-02 -9.99814746e-01  0.00000000e+00\n",
      "   9.80416992e-04]\n",
      " [ 2.59895684e-01 -1.00000000e+00  0.00000000e+00  2.59895684e-01\n",
      "   6.32328814e-02 -9.99627884e-01  0.00000000e+00  6.32328814e-02\n",
      "  -9.98900017e-01  2.53959985e-02 -1.00000000e+00  0.00000000e+00\n",
      "  -3.57181154e-03]\n",
      " [ 9.98477303e-01 -9.99908444e-01  0.00000000e+00  9.98477303e-01\n",
      "   2.74238860e-01 -9.95162491e-01  0.00000000e+00  2.74238860e-01\n",
      "  -9.98673178e-01  1.24834683e-01 -9.99445782e-01  0.00000000e+00\n",
      "   4.65270955e-03]\n",
      " [ 2.52244145e-01 -1.00000000e+00  0.00000000e+00  2.52244145e-01\n",
      "   4.02871817e-02 -9.99782932e-01  0.00000000e+00  4.02871817e-02\n",
      "  -9.98797697e-01  2.76201258e-02 -9.99876497e-01  0.00000000e+00\n",
      "   2.58470185e-02]\n",
      " [ 9.97709069e-01 -9.99908444e-01  0.00000000e+00  9.97709069e-01\n",
      "   7.18579394e-01 -9.84433143e-01  0.00000000e+00  7.18579394e-01\n",
      "  -9.98677348e-01  5.48311460e-01 -9.87388828e-01  0.00000000e+00\n",
      "   9.32241304e-02]\n",
      " [ 2.60857051e-01 -1.00000000e+00  0.00000000e+00  2.60857051e-01\n",
      "   8.13102379e-01 -9.84433143e-01  0.00000000e+00  8.13102379e-01\n",
      "  -9.98589311e-01  4.42485118e-01 -9.87435142e-01  0.00000000e+00\n",
      "   7.22530690e-02]\n",
      " [ 2.60468139e-01 -1.00000000e+00  0.00000000e+00  2.60468139e-01\n",
      "   1.00000000e+00 -9.84433143e-01  0.00000000e+00  1.00000000e+00\n",
      "  -9.98684609e-01  5.61461832e-01 -9.87435142e-01  0.00000000e+00\n",
      "   2.67729811e-01]\n",
      " [ 2.51914127e-01 -1.00000000e+00  0.00000000e+00  2.51914127e-01\n",
      "   8.07158558e-01 -9.84433143e-01  0.00000000e+00  8.07158558e-01\n",
      "  -9.98689367e-01  4.03448663e-01 -9.91726861e-01  0.00000000e+00\n",
      "   1.28054417e-01]\n",
      " [ 9.98178265e-01 -9.99908444e-01  0.00000000e+00  9.98178265e-01\n",
      "   5.32677869e-01 -9.84526172e-01  0.00000000e+00  5.32677869e-01\n",
      "  -9.98653407e-01  2.06617217e-01 -9.97066810e-01  0.00000000e+00\n",
      "   2.62786975e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"steps\">3 - Selection of a classification algorithm to wrap in our <span class=\"color7\"><strong>Feature Selection</strong></span> methodology</p>\n",
    "A <a href=\"https://en.wikipedia.org/wiki/Support-vector_machine\"><strong>Support Vector Machine <img src=\"../../images/icons/link.png\" width=\"10px\" height=\"10px\" style=\"display:inline\"></strong></a> shares some principles with <a href=\"https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm\"><strong>k-Nearest Neighbour Classifiers <img src=\"../../images/icons/link.png\" width=\"10px\" height=\"10px\" style=\"display:inline\"></strong></a> (which we want to use on <a href=\"../Train_and_Classify/classification_game_volume_4.ipynb\">Jupyter Notebook [volume 4] <img src=\"../../images/icons/link.png\" width=\"10px\" height=\"10px\" style=\"display:inline\"></a>), namely the Cartesian logic, given that each example corresponds to a point with a number $N$ of coordinates equivalent to the number of features analysed (13 for our original problem), that is, each feature defines a dimension of the space.\n",
    "<br>\n",
    "Because of this \"contact point\" our \"wrapped\" classifier will be a Support Vector Machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of a \"Support Vector Classifier\" supposing that  our classes are linearly separable.\n",
    "svc = SVC(kernel=\"linear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"steps\">4 - Configuration of the <span class=\"color4\">Recursive Feature Elimination</span> procedure given as an input our previously created \"svc\" object</p>\n",
    "Some inputs need to be given:\n",
    "<ul>\n",
    "    <li><strong>estimator</strong> - our previously created <i>\"Support Vector Classifier\"</i> object</li>\n",
    "    <li><strong>step</strong> - number of features eliminated on each iteration of the recursive algorithm</li>\n",
    "    <li><strong>cv</strong> - cross-validation method for estimating the quality of the \"virtual\" classifiers and dividing the original training set into $K$ subsets of training/test examples. The choice result in a <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html\"><strong>Stratified K-Fold Strategy <img src=\"../../images/icons/link.png\" width=\"10px\" height=\"10px\" style=\"display:inline\"></strong></a> (\"The folds are made by preserving the percentage of samples for each class\")</li>\n",
    "    <li><strong>scoring</strong> - definition of criteria for qualifying a classifier. For us the best classifier will be the one that achieve a great accuracy on classifying the test examples</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfecv = RFECV(estimator=svc, step=1, cv=StratifiedKFold(5), scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"steps\">5 - Execution of the <span class=\"color4\">Recursive Feature Elimination</span> procedure</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit data to the model.\n",
    "selector = rfecv.fit(features_list, class_training_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_in"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFECV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
      "      estimator=SVC(kernel='linear'), scoring='accuracy')\n"
     ]
    }
   ],
   "source": [
    "print(selector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"steps\">6 - Get the optimal number of features</p>\n",
    "It will be the smallest number that provides the possibility to obtain a highest cross-validation score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"steps\">6.1 - Get the list of average score of each virtual classifier (1 per Recursive Feature Elimination iteration)</p>\n",
    "The first element of the list refers to the average score of the trained classifiers when the set of features is 1, while the last one corresponds to the case where all features are taken into consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of average score of the virtual classifier\n",
    "# avg_scores = rfecv.grid_scores_\n",
    "avg_scores = rfecv.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_in"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7  0.9  0.9  0.9  0.9  0.75 0.75 0.75 0.75 0.75 0.75 0.75 0.75]\n"
     ]
    }
   ],
   "source": [
    "print(avg_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"steps\">6.2 - Identification of the maximum score</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_score = max(avg_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_in"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;98;195;238m\u001b[1mMaximum Average Score:\u001b[0m \u001b[39m0.9\n"
     ]
    }
   ],
   "source": [
    "print(fg(98,195,238) + \"\\033[1mMaximum Average Score:\\033[0m \" + fg.rs + str(max_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"steps\">6.3 - Identification of the smallest feature set that achieve the maximum score</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nbr_features in range(0, len(avg_scores)):\n",
    "    if avg_scores[nbr_features] == max_score:\n",
    "        optimal_nbr_features = nbr_features + 1\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_in"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;98;195;238m\u001b[1mOptimal Number of Features:\u001b[0m \u001b[39m2\n"
     ]
    }
   ],
   "source": [
    "print(fg(98,195,238) + \"\\033[1mOptimal Number of Features:\\033[0m \" + fg.rs + str(optimal_nbr_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_in"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div class=\"bk-root\" id=\"3c9858eb-fd40-457d-989a-47a5554286bb\" data-root-id=\"1002\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function embed_document(root) {\n  const docs_json = {\"1bfe815c-5fca-4cf5-890b-8a7634cc70a3\":{\"defs\":[],\"roots\":{\"references\":[{\"attributes\":{\"background_fill_color\":\"rgb(242, 242, 242)\",\"below\":[{\"id\":\"1012\"}],\"center\":[{\"id\":\"1015\"},{\"id\":\"1019\"}],\"height\":200,\"left\":[{\"id\":\"1016\"}],\"renderers\":[{\"id\":\"1038\"}],\"sizing_mode\":\"scale_width\",\"title\":null,\"toolbar\":{\"id\":\"1027\"},\"x_range\":{\"id\":\"1004\"},\"x_scale\":{\"id\":\"1008\"},\"y_range\":{\"id\":\"1006\"},\"y_scale\":{\"id\":\"1010\"}},\"id\":\"1002\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"1046\",\"type\":\"AllLabels\"},{\"attributes\":{},\"id\":\"1021\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"1017\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1047\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"1048\",\"type\":\"Selection\"},{\"attributes\":{\"overlay\":{\"id\":\"1026\"}},\"id\":\"1022\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"active_scroll\":{\"id\":\"1021\"},\"logo\":null,\"tools\":[{\"id\":\"1020\"},{\"id\":\"1021\"},{\"id\":\"1022\"},{\"id\":\"1024\"}]},\"id\":\"1027\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"1020\",\"type\":\"PanTool\"},{\"attributes\":{\"axis\":{\"id\":\"1016\"},\"coordinates\":null,\"dimension\":1,\"grid_line_color\":\"rgb(150, 150, 150)\",\"grid_line_dash\":[2,2],\"group\":null,\"ticker\":null},\"id\":\"1019\",\"type\":\"Grid\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#009EE3\",\"line_width\":2,\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1036\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"1006\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1013\",\"type\":\"BasicTicker\"},{\"attributes\":{\"bottom_units\":\"screen\",\"coordinates\":null,\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"group\":null,\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"syncable\":false,\"top_units\":\"screen\"},\"id\":\"1026\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"axis_label\":\"Number of features selected\",\"axis_line_color\":\"white\",\"coordinates\":null,\"formatter\":{\"id\":\"1045\"},\"group\":null,\"major_label_policy\":{\"id\":\"1046\"},\"major_label_text_color\":\"rgb(88, 88, 88)\",\"major_tick_line_color\":\"white\",\"minor_tick_line_color\":\"white\",\"ticker\":{\"id\":\"1013\"}},\"id\":\"1012\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1042\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1024\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"1045\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1043\",\"type\":\"AllLabels\"},{\"attributes\":{\"axis_label\":\"Cross validation score (nb of correct classifications)\",\"axis_line_color\":\"rgb(150, 150, 150)\",\"axis_line_dash\":[2,2],\"coordinates\":null,\"formatter\":{\"id\":\"1042\"},\"group\":null,\"major_label_policy\":{\"id\":\"1043\"},\"major_label_text_color\":\"rgb(88, 88, 88)\",\"major_tick_in\":0,\"major_tick_line_color\":\"white\",\"major_tick_out\":0,\"minor_tick_line_color\":\"white\",\"minor_tick_out\":0,\"ticker\":{\"id\":\"1017\"}},\"id\":\"1016\",\"type\":\"LinearAxis\"},{\"attributes\":{\"coordinates\":null,\"data_source\":{\"id\":\"1034\"},\"glyph\":{\"id\":\"1035\"},\"group\":null,\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"1037\"},\"nonselection_glyph\":{\"id\":\"1036\"},\"view\":{\"id\":\"1039\"}},\"id\":\"1038\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"source\":{\"id\":\"1034\"}},\"id\":\"1039\",\"type\":\"CDSView\"},{\"attributes\":{\"axis\":{\"id\":\"1012\"},\"coordinates\":null,\"grid_line_color\":\"rgb(150, 150, 150)\",\"grid_line_dash\":[2,2],\"group\":null,\"ticker\":null},\"id\":\"1015\",\"type\":\"Grid\"},{\"attributes\":{\"line_color\":\"#009EE3\",\"line_width\":2,\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1035\",\"type\":\"Line\"},{\"attributes\":{\"line_alpha\":0.2,\"line_color\":\"#009EE3\",\"line_width\":2,\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1037\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"1008\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1004\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1010\",\"type\":\"LinearScale\"},{\"attributes\":{\"data\":{\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13],\"y\":[0.7,0.9,0.9,0.9,0.9,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75]},\"selected\":{\"id\":\"1048\"},\"selection_policy\":{\"id\":\"1047\"}},\"id\":\"1034\",\"type\":\"ColumnDataSource\"}],\"root_ids\":[\"1002\"]},\"title\":\"Bokeh Application\",\"version\":\"2.4.3\"}};\n  const render_items = [{\"docid\":\"1bfe815c-5fca-4cf5-890b-8a7634cc70a3\",\"root_ids\":[\"1002\"],\"roots\":{\"1002\":\"3c9858eb-fd40-457d-989a-47a5554286bb\"}}];\n  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n  }\n  if (root.Bokeh !== undefined) {\n    embed_document(root);\n  } else {\n    let attempts = 0;\n    const timer = setInterval(function(root) {\n      if (root.Bokeh !== undefined) {\n        clearInterval(timer);\n        embed_document(root);\n      } else {\n        attempts++;\n        if (attempts > 100) {\n          clearInterval(timer);\n          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n        }\n      }\n    }, 10, root)\n  }\n})(window);",
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1002"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bsnb.plot([range(1, len(rfecv.cv_results_['mean_test_score']) + 1)], [avg_scores], \n",
    "          y_axis_label=\"Cross validation score (nb of correct classifications)\", x_axis_label=\"Number of features selected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"steps\">7 - Identification of the set of relevant features, taking into consideration the previously determined optimal number</p>\n",
    "It should be repeated the Recursive Feature Elimination procedure with \"RFE\" scikit-learn function, specifying the desired number of target features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rfe = RFE(estimator=svc, step=1, n_features_to_select=optimal_nbr_features)\n",
    "\n",
    "# Fit data to the model.\n",
    "final_selector = rfe.fit(features_list, class_training_examples)\n",
    "\n",
    "# Acception/Rejection Label attributed to each feature.\n",
    "acception_labels = final_selector.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_in"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;98;195;238m\u001b[1mRelevant Features (True):\u001b[0m \u001b[39m\n",
      "[False False False False False False False False False  True False False\n",
      "  True]\n"
     ]
    }
   ],
   "source": [
    "print(fg(98,195,238) + \"\\033[1mRelevant Features (True):\\033[0m \" + fg.rs)\n",
    "print(acception_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each training array has the following structure/content:\n",
    "<br>\n",
    "\\[$\\sigma_{emg\\,flexor}$, $max_{emg\\,flexor}$, $zcr_{emg\\,flexor}$, $\\sigma_{emg\\,flexor}^{abs}$, $\\sigma_{emg\\,adductor}$, $max_{emg\\,adductor}$, $zcr_{emg\\,adductor}$, $\\sigma_{emg\\,adductor}^{abs}$, $\\mu_{acc\\,z}$, $\\sigma_{acc\\,z}$, $max_{acc\\,z}$, $zcr_{acc\\,z}$, $m_{acc\\,z}$\\] \n",
    "\n",
    "So, the relevant features are:\n",
    "<ul>\n",
    "    <li>$\\sigma_{emg\\,flexor}$</li>\n",
    "    <li>$zcr_{emg\\,flexor}$</li>\n",
    "    <li>$\\sigma_{emg\\,flexor}^{abs}$</li>\n",
    "    <li>$\\sigma_{emg\\,adductor}$</li>\n",
    "    <li>$\\sigma_{emg\\,adductor}^{abs}$</li>\n",
    "    <li>$\\sigma_{acc\\,z}$</li>\n",
    "    <li>$max_{acc\\,z}$</li>\n",
    "    <li>$m_{acc\\,z}$</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"steps\">8 - Removal of meaningless features from our \"features_list\" list</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access each training example and exclude meaningless entries.\n",
    "final_features_list = []\n",
    "for example_nbr in range(0, len(features_list)):\n",
    "    final_features_list += [list(array(features_list[example_nbr])[array(acception_labels)])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"steps\">9 - Storage of the final list of features (after <i>Recursive Feature Elimination</i>) inside a .json file</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"classification_game_features_final.json\"\n",
    "\n",
    "# Generation of .json file in our previously mentioned \"relative_path\".\n",
    "# [Generation of new file]\n",
    "with open(relative_path + \"/\" + filename, 'w') as file:\n",
    "    dump({\"features_list_final\": final_features_list, \"class_labels\": class_training_examples}, file)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "env_rwis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
